{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regularized logistic regression to classify email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "from sklearn import linear_model\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Penalty experiments -----------\n",
      "best_lambda = 0.100\n",
      "Coefficients = [-4.86264099] [[-2.75863912e-02 -2.25520829e-01  1.21633316e-01  2.29715639e+00\n",
      "   2.70389525e-01  2.32758703e-01  9.28696739e-01  2.95108646e-01\n",
      "   1.62231043e-01  6.87327938e-02 -8.34295167e-02 -1.60453362e-01\n",
      "  -4.73831093e-02  1.08099581e-02  1.89106435e-01  8.19579715e-01\n",
      "   5.09743414e-01  3.96564290e-02  2.67580695e-01  3.46287865e-01\n",
      "   2.60096924e-01  3.66028669e-01  7.25798414e-01  1.96647549e-01\n",
      "  -3.15432669e+00 -4.03241347e-01 -1.25431026e+01 -6.03475492e-02\n",
      "  -1.55900780e+00 -5.54192358e-02 -3.22608889e-02  4.09403864e-01\n",
      "  -3.68453591e-01 -1.44128010e+00 -5.91171090e-01  4.43379921e-01\n",
      "   4.24214409e-02 -1.56891563e-01 -4.54976317e-01 -1.02134658e-01\n",
      "  -3.54371315e+00 -1.72832251e+00 -4.38062910e-01 -1.06014026e+00\n",
      "  -9.18429801e-01 -1.75378492e+00 -1.67358763e-01 -9.57894856e-01\n",
      "  -3.66419635e-01 -1.36363345e-01 -6.58938785e-02  2.06744541e-01\n",
      "   1.70779761e+00  1.21449393e+00 -3.36700002e-01  1.56505453e+00\n",
      "   3.68165406e-01]]\n",
      "Accuracy on set aside test set for std = 0.9297\n",
      "best_lambda = 0.600\n",
      "Coefficients = [-4.60944585] [[-0.45145867 -0.28466491 -0.06327675  0.68295818  1.21053206  0.91505018\n",
      "   2.83046292  1.4367806   0.24145473  0.35775877 -0.38642934 -0.48142849\n",
      "  -0.69586888  0.37456985  0.64885492  1.53956277  1.38118255  0.071977\n",
      "   0.37642326  0.63501979  0.52274723  0.38563732  2.00138775  1.50817386\n",
      "  -3.140609   -0.66617002 -4.90648511 -0.03260318 -1.2888633  -0.15745813\n",
      "  -0.63899811 -0.30229293 -1.00990157 -0.42568657 -1.08721724  1.28433069\n",
      "  -0.90558908 -0.35285909 -1.12971434 -0.62589463 -1.40337107 -2.4412348\n",
      "  -1.55653469 -1.94778086 -1.13113717 -2.79991208 -0.75122292 -2.11602125\n",
      "  -1.68510914 -0.66773502 -0.69125615  2.06913109  4.21977678  0.76308916\n",
      "   0.703458    0.17008534  0.43018825]]\n",
      "Accuracy on set aside test set for logt = 0.9434\n",
      "best_lambda = 1.100\n",
      "Coefficients = [-1.83742964] [[-1.91463198e-01 -1.66872958e-01 -3.93802023e-01  2.39462779e-01\n",
      "   9.83292893e-01  1.75311415e-01  2.12183419e+00  7.92547596e-01\n",
      "   1.94566579e-01  3.34388296e-01 -2.90824615e-01 -4.20297340e-01\n",
      "  -9.06380382e-01  2.56299856e-01  5.15189474e-01  1.47014136e+00\n",
      "   8.76696475e-01 -8.32760955e-02  2.41264180e-01  5.01801273e-01\n",
      "   7.37046896e-01  1.15518007e+00  9.11195183e-01  1.36902984e+00\n",
      "  -2.35248856e+00 -4.17190307e-01 -3.79772643e+00  6.88337610e-01\n",
      "  -6.07237597e-01 -1.61622832e-01 -9.24671805e-01 -6.04558746e-01\n",
      "  -6.91161481e-01 -3.85638236e-02 -6.71440135e-01  3.52732370e-01\n",
      "  -1.05408408e+00  5.28551479e-01 -7.65306731e-01 -2.46067578e-01\n",
      "  -1.27643951e+00 -1.90613122e+00 -7.90184279e-01 -1.57619158e+00\n",
      "  -7.64312034e-01 -2.22366816e+00 -8.34144233e-02 -1.39371572e+00\n",
      "  -3.06993897e-01  2.00231957e-01 -1.70968578e-01  1.20762876e+00\n",
      "   1.45771409e+00  3.79908684e-02  5.31811819e-04  5.31811819e-04\n",
      "   5.31811819e-04]]\n",
      "Accuracy on set aside test set for bin = 0.9277\n",
      "L1 Penalty experiments -----------\n",
      "best_lambda = 4.600\n",
      "Coefficients = [-1.59483195] [[-0.0106687  -0.15874361  0.12269084  0.20795651  0.2491453   0.17702386\n",
      "   0.91010142  0.28984109  0.13970132  0.04856363 -0.02304592 -0.13984822\n",
      "  -0.00706946  0.00920042  0.15332047  0.75697122  0.45988311  0.0703704\n",
      "   0.25407583  0.19631378  0.24327995  0.3465016   0.72588678  0.23412078\n",
      "  -2.33944947 -0.35833228 -3.17782292 -0.01080041 -0.37064974  0.\n",
      "   0.          0.         -0.32753551  0.         -0.061446    0.2424959\n",
      "   0.         -0.11600013 -0.31159798 -0.04362879 -0.23964514 -0.79597017\n",
      "  -0.19076948 -0.56438211 -0.73388682 -1.18112577 -0.08549707 -0.51346057\n",
      "  -0.25640325 -0.13353228 -0.05666502  0.21826151  1.64763239  0.22133048\n",
      "   0.          0.64780927  0.33273002]]\n",
      "Accuracy on set aside test set for std = 0.9219\n",
      "best_lambda = 1.600\n",
      "Coefficients = [-4.46285628] [[-0.34349837 -0.09572387  0.          0.1294076   1.1845862   0.69045618\n",
      "   2.91330682  1.37686972  0.          0.29510548  0.         -0.48054747\n",
      "  -0.32805256  0.10732133  0.          1.49530065  1.3490769   0.\n",
      "   0.35498362  0.19665242  0.49436858  0.34764889  1.78468354  1.32945399\n",
      "  -3.49778522 -0.26965853 -7.49402471  0.         -0.41757038  0.\n",
      "   0.          0.         -0.7913621   0.         -0.23874344  0.87184781\n",
      "  -0.77437138  0.         -0.88300961  0.         -0.30387974 -2.35510569\n",
      "  -0.69473593 -1.6613146  -1.13792579 -2.98267988  0.         -1.90113584\n",
      "  -1.24509136 -0.30324665  0.          2.0146499   5.36667293  0.\n",
      "   0.63655828  0.20204836  0.38798838]]\n",
      "Accuracy on set aside test set for logt = 0.9440\n",
      "best_lambda = 3.600\n",
      "Coefficients = [-0.3478434] [[ 0.          0.         -0.19355159  0.          0.86605664  0.\n",
      "   2.02965071  0.63324199  0.02659849  0.21257673  0.         -0.42140666\n",
      "  -0.68105877  0.          0.          1.31578131  0.76600023  0.\n",
      "   0.10695208  0.1226669   0.6353628   0.73039146  0.62146149  1.18367253\n",
      "  -2.42482738 -0.12487958 -3.73142949  0.          0.          0.\n",
      "   0.          0.         -0.28811041  0.         -0.21914402  0.\n",
      "  -1.01549413  0.         -0.40509641  0.         -0.11530932 -1.69453416\n",
      "  -0.03913255 -1.11015544 -0.68760747 -2.21950089  0.         -1.02566275\n",
      "  -0.1250519   0.07402047  0.          1.15084872  1.50022906  0.\n",
      "  -0.89161551 -0.17374173 -0.25316007]]\n",
      "Accuracy on set aside test set for bin = 0.9258\n"
     ]
    }
   ],
   "source": [
    "# No modifications in this cell\n",
    "# complete the functions in utils.py; then run the cell\n",
    "\n",
    "# load the spam data in\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = utils.load_spam_data()\n",
    "\n",
    "# Preprocess the data \n",
    "\n",
    "Xtrain_std,mu,sigma = utils.std_features(Xtrain)\n",
    "Xtrain_logt = utils.log_features(Xtrain)\n",
    "Xtrain_bin = utils.bin_features(Xtrain)\n",
    "\n",
    "Xtest_std = (Xtest - mu)/sigma\n",
    "Xtest_logt = utils.log_features(Xtest)\n",
    "Xtest_bin = utils.bin_features(Xtest)\n",
    "\n",
    "# find good lambda by cross validation for these three sets\n",
    "\n",
    "def run_dataset(X,ytrain,Xt,ytest,typea,penalty):\n",
    "\n",
    "    best_lambda = utils.select_lambda_crossval(X,ytrain,0.1,5.1,0.5,penalty)\n",
    "    print(\"best_lambda = %.3f\" %best_lambda)\n",
    "\n",
    "    # train a classifier on best_lambda and run it\n",
    "    if penalty == \"l2\":\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='lbfgs',fit_intercept=True)\n",
    "    else:\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='liblinear',fit_intercept=True)\n",
    "    lreg.fit(X,ytrain)\n",
    "    print(\"Coefficients = %s\" %lreg.intercept_,lreg.coef_)\n",
    "    predy = lreg.predict(Xt)\n",
    "    print(\"Accuracy on set aside test set for %s = %.4f\" %(typea, np.mean(predy==ytest)))\n",
    "\n",
    "print(\"L2 Penalty experiments -----------\")\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l2\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l2\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l2\")\n",
    "\n",
    "print(\"L1 Penalty experiments -----------\")\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l1\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l1\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
